[{"content":"The intent of this post is not to simply rehash Anthropic\u0026rsquo;s1 report, as you can read that HERE; rather, my goals are to outline AI\u0026rsquo;s role in this campaign, present strategies for hunting AI-driven operations, and highlight how that may differ from traditional human operations.\nOverview\rIn mid-September 2025, a landmark shift in the cyber threat landscape was uncovered: the first documented case of a large-scale, AI-orchestrated cyber espionage campaign. Conducted by a Chinese state-sponsored group designated as GTG-1002, the operation targeted approximately 30 entities, including major technology corporations, government agencies, and financial institutions. This campaign represents a fundamental evolution in offensive capabilities, where human operators shifted from performing tactical work to acting as strategic supervisors, leaving 80-90% of the active intrusion tasks to autonomous AI agents.\nThe GTG-1002 campaign utilized an autonomous attack framework built around Claude Code and the Model Context Protocol (MCP). By manipulating AI instances into role-playing as defensive security professionals, the threat actors induced the AI to perform reconnaissance, vulnerability discovery, and data exfiltration across multiple targets simultaneously. Unlike traditional attacks where AI merely \u0026ldquo;advises,\u0026rdquo; this framework functioned as an execution engine, maintaining attack states and managing transitions between phases with minimal human oversight.\nThe Attack Lifecycle and AI Integration\rThe campaign followed a multi-stage intrusion sequence typical of advanced persistent threats — but with AI deeply integrated throughout each phase.\nPhase 1: Campaign Initialization\nHuman operators selected high-value targets and \u0026ldquo;socially engineered\u0026rdquo; the AI by convincing it that it was conducting authorized defensive testing.\nAI Role: Minimal, as humans conducted the social-engineering and target selection.\nPhase 2: Reconnaissance\nClaude systematically cataloged infrastructure, analyzed authentication, and mapped network topologies.\nAI Role: Fully autonomous, conducting reconnaissance against hundreds of endpoints and mapping internal services across multiple IP ranges simultaneously.\nPhase 3: Vulnerability Discovery and Validation\nThe AI generated custom payloads tailored to discovered vulnerabilities (such as SSRF) and executed them via remote interfaces.\nAI Role: Autonomous execution. The AI validated exploits through callback communication systems and only requested human approval at the final escalation point.\nPhase 4: Credential Harvesting and Lateral Movement\nOnce inside, the AI queried internal services, extracted certificates, and tested them across the environment to map privilege levels.\nAI Role: Self-directed. The AI independently determined which credentials worked on which systems, moving laterally across APIs and container registries.\nPhase 5: Data Collection and Intelligence Extraction\nThe AI queried databases, parsed results for proprietary data, and categorized findings by their intelligence value.\nAI Role: Analysis-heavy. The AI acted as a data scientist, identifying high-value info without manual human parsing.\nPhase 6: Documentation and Handoff\nThroughout the campaign, the AI generated structured markdown files detailing every service found, credential stolen, and exploit used.\nAI Role: Fully autonomous record-keeping. This allowed different human teams to resume complex operations seamlessly.\nWhile the attack chain doesn\u0026rsquo;t really differ from that of a human-led campaign, we can see that the role AI played in this operation allowed for scalability that otherwise could not be achieved.\nThreat Hunting Strategies for AI-Driven Operations\rTraditional threat hunting assumes adversaries with predictable patterns and human decision-making cycles. AI-orchestrated operations, however, require reevaluating detection strategies across the kill chain with a shift in focus from \u0026ldquo;human-like\u0026rdquo; behaviors to \u0026ldquo;machine-speed\u0026rdquo; patterns. What Anthropic documented is not “AI helping a hacker” — it is AI acting as the primary operator, with humans serving as approval gates. This fundamentally changes what we hunt for and how we hunt.\nOperational Tempo\rThe most immediate differentiator between AI-driven and traditional operations is the sheer volume and rate of activity.\nHuman-Led Activity\nTypically follows a \u0026ldquo;bursty\u0026rdquo; pattern. An operator researches a tool, types a command, waits for output, and analyzes it before the next step. This creates natural pauses and a tempo consistent with human interaction.\nAI-Orchestrated Activity\nIn the GTG-1002 campaign, peak activity reached thousands of requests, representing sustained rates of multiple operations per second — a frequency physically impossible for human operators.\nHunting\nSearch for sequential activity that would be \u0026ldquo;physically impossible\u0026rdquo; for a human operator. Traditional rate-limiting often targets brute-force attempts, but here, defenders must hunt for a high volume of varied tactical commands (such as service discovery followed immediately by exploit validation) occurring within milliseconds of each other. In the example query below, we are looking for a single source IP interacting with an unusually high number of unique internal destinations or URLs in a very short window.\nFROM logs-endpoint, logs-network | WHERE event.category == \u0026#34;network\u0026#34; AND network.direction == \u0026#34;internal\u0026#34; | STATS unique_dest = COUNT_DISTINCT(destination.address), total_req = COUNT(*) BY source.address, bin(timestamp, 1s) | WHERE unique_dest \u0026gt; 50 OR total_req \u0026gt; 100 | SORT timestamp DESC This query buckets network logs into 1-second windows. It calculates how many unique internal addresses a single source reached out to per second. A human might click a link or run a script that hits 5–10 endpoints, but an AI agent mapping a network will often hit 50+ unique destinations or ports per second as it \u0026ldquo;thinks\u0026rdquo; through the topology.\nData Input vs Text Output Disparity\rA key indicator of AI-driven post-exploitation is how data is processed within the environment.\nHuman-Led Activity\nHumans often exfiltrate raw data (files, database dumps) to analyze it offline. If they analyze it on-site, logs typically show interactive commands like grep, awk, or manual file opens.\nAI-Orchestrated Activity\nAI agents, such as Claude in this operation, can parse enormous volumes of stolen information locally or via an orchestration proxy to identify intelligence value.\nHunting\nLook for a massive disparity between the volume of data inputs (such as thousands of database queries or file reads) and the relatively small volume of text outputs or exfiltrated \u0026ldquo;summary\u0026rdquo; files. This suggests an automated engine is distilling vast datasets into concise intelligence reports. In the example query below, the goal is to identify AI behavior by finding hosts that are reading large volumes of data (input) but sending back very small, highly structured summary files (output).\nFROM logs-network, logs-endpoint | WHERE event.action == \u0026#34;file_read\u0026#34; OR event.action == \u0026#34;exfiltration\u0026#34; | STATS bytes_read = SUM(file.size), bytes_out = SUM(network.bytes) BY host.name, user.name | EVAL ratio = bytes_read / bytes_out | WHERE bytes_read \u0026gt; 100000000 AND ratio \u0026gt; 1000 | SORT ratio DESC This query compares the total bytes a user \u0026ldquo;read\u0026rdquo; from the disk/databases versus what they sent over the wire. In a traditional smash and grab human theft, the ratio is close to 1:1. Here, we look for a Ratio \u0026gt; 1000, meaning for every 1GB read, only 1MB was sent out; this would be a sign of an AI agent summarizing logs, database rows, or codebases into a markdown report before exfiltrating.\nState Preservation and Session Persistence\rAI agents solve the \u0026ldquo;hands-off\u0026rdquo; problem that often plagues human-led state-sponsored teams.\nHuman-Led Activity\nWhen shifts change or campaigns resume after a break, there is often a \u0026ldquo;re-reconnaissance\u0026rdquo; phase where the new operator verifies previous findings, leading to redundant logs.\nAI-Orchestrated Activity\nClaude maintained persistent operational context across sessions spanning multiple days, allowing complex campaigns to resume seamlessly without human reconstruction. Furthermore, the AI generated structured markdown documentation automatically, tracking every credential and technique discovered.\nHunting\nAnalyze the \u0026ldquo;resumption fingerprint.\u0026rdquo; If an intrusion resumes after a 48-hour quiet period and immediately executes perfectly targeted commands against previously discovered internal APIs — without any repeat reconnaissance — it strongly suggests a persistent AI state rather than a human operator re-orienting themselves. The GTG-1002 report also highlighted that Claude Code and similar agents maintain attack states in structured files (Markdown or JSON). We could attempt to hunt on this state preservation and session persistence by identifying the creation and constant updating of these files.\nFROM logs-endpoint | WHERE event.action == \u0026#34;file_modify_event\u0026#34; | WHERE file.extension IN (\u0026#34;json\u0026#34;, \u0026#34;md\u0026#34;, \u0026#34;yaml\u0026#34;) | STATS update_count = COUNT(*), unique_files = COUNT_DISTINCT(file.path) BY process.executable, host.name | WHERE update_count \u0026gt; 100 AND unique_files \u0026lt; 5 | WHERE process.executable LIKE \u0026#34;*python*\u0026#34; OR process.executable LIKE \u0026#34;*node*\u0026#34; Normal users don\u0026rsquo;t update a single JSON or Markdown file hundreds of times an hour via a script engine (Node.js/Python). This query identifies a process that is \u0026ldquo;logging its thoughts\u0026rdquo; or updating a database of \u0026ldquo;discovered assets\u0026rdquo; in real-time. This is the \u0026ldquo;brain\u0026rdquo; of the AI agent living on the disk.\nDetecting the Model Context Protocol (MCP) and Tooling Proxies\rThe technical architecture of these attacks often relies on standardized protocols to bridge the AI to the target environment. The GTG-1002 framework used Claude Code and the Open Model Context Protocol (MCP) to conduct operations. The AI was effectively an \u0026ldquo;execution engine\u0026rdquo; within an automated system that decomposed complex attacks into discrete technical tasks.\nHunting\nWe can monitor for unusual traffic patterns or headers associated with MCP servers being used as \u0026ldquo;tool call proxies\u0026rdquo; to interface with internal target services, or for traffic originating from \u0026ldquo;neutral party\u0026rdquo; callback services used by the AI to validate exploits autonomously. We can also attempt to identify artifacts associated with MCP or Claude Code execution. Even better, we can look for behavioral indicators of tooling execution via AI. A standard application typically spawns a predictable set of child processes; an AI agent, however will often spawn a high diversity of unique utilities from a single parent process in a very tight temporal window.\nFROM logs-endpoint | WHERE event.category == \u0026#34;process\u0026#34; AND event.type == \u0026#34;start\u0026#34; | // Filter for common discovery/exploitation tools often called by agents | WHERE process.name IN (\u0026#34;whoami.exe\u0026#34;, \u0026#34;net.exe\u0026#34;, \u0026#34;hostname.exe\u0026#34;, \u0026#34;ipconfig.exe\u0026#34;, \u0026#34;systeminfo.exe\u0026#34;, \u0026#34;nltest.exe\u0026#34;, \u0026#34;netstat.exe\u0026#34;, \u0026#34;curl.exe\u0026#34;) | STATS unique_tools_count = COUNT_DISTINCT(process.name), tool_list = COLLECT_DISTINCT(process.name) BY process.parent.entity_id, process.parent.executable, bin(timestamp, 10s) | WHERE unique_tools_count \u0026gt;= 5 | SORT unique_tools_count DESC This query identifies any parent process that spawns more than 5 unique \u0026ldquo;Living off the Land\u0026rdquo; or discovery utilities within a 10-second window — a pattern typical of an AI agent iterating through a tool-calling loop.\nLeverage \u0026ldquo;AI Hallucination\u0026rdquo;\rIn Anthropic\u0026rsquo;s report, they noted that Claude frequently overstated findings or fabricated data, such as claiming to have obtained working credentials that were actually non-existent or public information, or even trying to exploit vulnerabilities that didn\u0026rsquo;t exist. This presents a defensive opportunity to take advantage of these flaws.\nHunting\nOne way we could attempt to combat agentic operations is via honeypots. While traditional honeytokens do the job, \u0026ldquo;hallucination bait\u0026rdquo; would likely be even more effective for AI operations. This would involve placing complex, legitimate-looking - but subtly flawed - configuration files in internal environments. A human might spot the flaw through experience, but an AI agent may confidently \u0026ldquo;validate\u0026rdquo; and attempt to use the fabricated data, creating a high-fidelity alert when the agent acts on its own hallucination .\nFROM logs-auth, logs-network | WHERE destination.address == \u0026#34;honeypot_ip\u0026#34; // Your Honey-IP OR user.name == \u0026#34;honeypot_user\u0026#34; // Your Honey-User | STATS count() BY source.ip, event.action | SORT timestamp DESC This a really simple, but certainly high-fidelity alert. If we place the \u0026ldquo;hallucination bait\u0026rdquo; file containing a fake IP and username, any traffic to that IP or use of those credentials would be an immediate red flag. While a human may validate discovered credentials, an AI agent would likely scrape the file and attempt to use the credentials.\nFinal Thoughts\rThe hunting strategies outlined here don\u0026rsquo;t even begin to scratch the surface of what defending against AI-orchestrated operations will require. What Anthropic documented is not simply a new toolset in the hands of attackers, but a structural change in how intrusion activity can be generated, scaled, and adapted in real time. Once an autonomous system is capable of independently enumerating environments, generating exploits, pivoting laterally, extracting intelligence, and refining its own approach faster than defenders can respond, compromise is no longer constrained by attacker fatigue, expertise, or other human limitations.\nAs a result, threat hunting can no longer rely solely on known techniques, familiar tools, or linear kill-chain assumptions. Hunting for AI-orchestrated activity requires a different perspective that focuses on detecting operational anomalies that would otherwise be impossible for a human operator to achieve; defenders must learn to recognize what cannot be done by a person, even a highly skilled one, and treat those patterns as indicators of potential compromise. The future of threat hunting will not be about keeping pace with AI-enabled attackers, but about redefining how we observe, reason about, and disrupt autonomous adversaries before they can fully leverage their speed and scale.\nDisrupting the First Reported AI-Orchestrated Cyber Espionage Campaign. (2025). Anthropic PBC. https://www.anthropic.com/news/disrupting-AI-espionage\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-12-23T00:00:00Z","image":"http://localhost:1313/post/agenticespionage/agenticespionage_hu_56c21eeabe2e0db5.png","permalink":"http://localhost:1313/post/agenticespionage/","title":"Agentic Espionage"},{"content":"Overview\rNow that I\u0026rsquo;ve covered the basics of threat hunting, let\u0026rsquo;s pivot to threat intelligence. The intent of this writeup is to provide a simple, broad overview of threat intelligence, and to touch on how threat intelligence integrates with threat hunting.\nThreat Intelligence (TI) is the practice of collecting, analyzing, and operationalizing information about adversaries, their capabilities, infrastructure, and intent to inform security decision‑making. Where threat hunting is proactive detection inside your environment, threat intelligence provides the external context that helps you decide what to hunt for, why it matters, and how attackers are likely to operate.\nA mature threat intelligence program does not exist to produce reports for their own sake — it exists to reduce risk, improve detection, and enable faster, more confident response.\nWhat is Threat Intelligence\rWhat It Is\rEvidence‑based insight about adversaries, campaigns, tools, techniques, and infrastructure Contextualized analysis that supports prevention, detection, response, and strategic planning Intelligence that is actionable, timely, and relevant to your organization What It Is Not\rA raw feed of IPs, hashes, or domains with no context A replacement for detection engineering, threat hunting, or incident response A one‑time project or a purely vendor‑driven capability Pillars of Threat Intelligence\rNot all intelligence is created equally. To be effective, intel must be tailored for both audience and focus. There are four primary \u0026ldquo;pillars\u0026rdquo; of intelligence that we will discuss. The distinction between each of these four types is the difference between a reactive SOC and a proactive security program.\nStrategic Intelligence\rTarget Audience: CISOs, Board Members, Executives, Risk Leaders Focus: High-level trends, risk landscape, and geopolitical shifts Example: A report on how AI-driven phishing is specifically targeting the financial sector\u0026rsquo;s regional banks Operational Intelligence\rTarget Audience: SOC Managers, IR Leaders Focus: Details on specific campaigns, intrusion sets, and attacker workflows Example: A walkthrough of a specific ransomware campaign from initial access to data exfiltration Tactical Intelligence\rTarget Audience: CISOs, SOC Analysts, Detection Engineers, Threat Hunters Focus: TTPs, MITRE ATT\u0026amp;CK mappings - the mechanics of an attack Example: Adversaries abusing OAuth apps for persistence in cloud tenants Technical Intelligence\rTarget Audience: SIEMs, EDR Systems, other SOC Tools and Automation Focus: IOCs like IPs, hashes and domains - machine-readable data Example: A list of 500 malicious IP addresses associated with a current ransomware campaign. Sources of Threat Intelligence\rOpen-Source Intelligence (OSINT)\rOSINT is the process of collecting and analyzing information that is publicly available. It is the \u0026ldquo;free\u0026rdquo; foundation of most CTI programs.\nGovernment \u0026amp; Regulatory Feeds\nReports from agencies like CISA (Known Exploited Vulnerabilities catalog) or FBI InfraGard.\nSecurity Blogs \u0026amp; Research\nDeep dives from companies like Mandiant, SentinelOne, or independent researchers on platforms like X (Twitter) or Mastodon.\nTechnical Repositories\nScanning tools like Shodan (for internet-connected devices) or VirusTotal (for checking if a file is malicious).\nVulnerability Databases\nThe CVE (Common Vulnerabilities and Exposures) list tells you which software bugs are currently being exploited in the wild.\nCommercial Intelligence Vendors\rIf OSINT is the local news, Commercial Intelligence is a private investigative firm. Organizations pay for these services to get high-fidelity data that isn\u0026rsquo;t available to the general public.\nProprietary Telemetry\nVendors like CrowdStrike or Microsoft see what is happening across millions of global endpoints. They turn this massive data set into \u0026ldquo;early warnings\u0026rdquo; for their customers.\nAdversary Dossiers\nDeep-dive profiles on specific hacker groups. Instead of just \u0026ldquo;an IP address,\u0026rdquo; you get a report on \u0026ldquo;Fancy Bear\u0026rdquo; (a Russian state actor), including their typical office hours, preferred malware, and historical targets.\nFinished Intelligence\nHuman-curated reports that explain the \u0026ldquo;So What?\u0026rdquo; for executives. This saves your team hours of manual research by providing \u0026ldquo;ready-to-consume\u0026rdquo; analysis.\nData Breach \u0026amp; Dark Web Monitoring\nMany vendors (like Recorded Future or ZeroFox) specifically crawl illicit marketplaces to see if your company\u0026rsquo;s leaked credentials or \u0026ldquo;stolen\u0026rdquo; data are being sold before a breach becomes public.\nInformation Sharing Communities\rThis sits between public and private intelligence and often reqeuires more specialized access.\nISACs (Information Sharing and Analysis Centers)\nIndustry-specific groups (e.g., FS-ISAC for Finance, H-ISAC for Healthcare) where competitors share threat data to protect the whole sector.\nDark Web Monitoring\nSpecialized tools that \u0026ldquo;scrape\u0026rdquo; illicit forums and marketplaces to see if your company\u0026rsquo;s credentials or \u0026ldquo;leaked\u0026rdquo; data are being sold.\nSOCMINT (Social Media Intelligence)\nMonitoring social trends to spot coordinated \u0026ldquo;hacktivist\u0026rdquo; campaigns or early mentions of a new zero-day exploit.\nInternal Intelligence\rInternal intelligence is often the most valuable because it is 100% relevant to your specific environment.\nEndpoint Telemetry (EDR/XDR)\nYour local \u0026ldquo;black boxes.\u0026rdquo; These provide details on process executions, registry changes, and lateral movement attempts.\nNetwork \u0026amp; Flow Logs\nFirewall, DNS, and Proxy logs. These reveal where your data is going and if your machines are \u0026ldquo;calling home\u0026rdquo; to a Command \u0026amp; Control (C2) server.\nIncident Response (IR) Reports\nLooking at past \u0026ldquo;post-mortems\u0026rdquo; from your own company. Attackers often return to the same victim using the same methods if they weren\u0026rsquo;t fully evicted.\nInternal Honeypots\nDecoy systems like \u0026ldquo;fake\u0026rdquo; file servers or unpatched databases. Anyone touching these is automatically a high-fidelity threat.\nThreat Intelligence Lifecycle\rLike threat hunting, threat intelligence follows a repeatable, structured lifecycle to ensure consistency and impact.\n1. Planning and Direction\nIntelligence analysts must first define what intelligence questions need answered. For example:\nWhich ransomware groups target organizations in our industry? What cloud‑focused attack techniques are trending right now? Which vulnerabilities are most likely to be exploited against us? These questions can/should be driven by concerns such as business risks, threat model gaps, and detection/response priorities.\n2. Collection\nOnce a question has been defined, data must be gathered from both internal and external sources.\nInternal sources:\nSIEM and EDR telemetry Incident response reports Threat hunting findings External sources:\nOSINT Commercial intel feeds Vendor reports and advisories Government and ISAC sharing 3. Processing\nIn this stage of the lifecycle analysts need to \u0026lsquo;clean\u0026rsquo; the data by normalizing, enriching, and structuring. For example:\nParsing indicators into structured formats Enriching IPs and domains with ASN, geolocation, or reputation Mapping observed activity to MITRE ATT\u0026amp;CK 4. Analysis\nTurn processed data into a \u0026ldquo;story.\u0026rdquo; This is where analysts identify patterns and provide context, answering questions such as:\nWhat happened? Why does it matter? How does this affect us specifically? 5. Dissemination\nOf course, none of this really matters until the right information is passed along to the right people. Depending on the content, intelligence reports need to be disseminated to the appropriate audience:\nExecutive briefs SOC-ready detection recommendations Threat hunting leads Incident response playbooks 6. Feedback and Refinement\nReporting should be reviewed for usefulness, relevance, and impact, and then improved upon for the next cycle. Some key considerations include:\nDid this intel change a decision? Did it improve detections or response? Was it timely and relevant? Threat Intelligence vs Threat Hunting\rThreat intelligence and threat hunting are mutually reinforcing.\nThreat Intelligence enables Hunting by:\nIdentifying relevant adversaries Highlighting emerging techniques Providing hypotheses to test Threat Hunting feeds Intelligence by:\nValidating or disproving reports Discovering novel activity Adding environment‑specific context Operationalizing Threat Intelligence\rLike with threat hunting, threat intelligence needs to result in actionable improvements to be useful, impactful, and successful. With the appropriate audience and focus, threat intel can drastically improve many processes across a security team.\nDetection Engineering\nTranslate TTPs into SIEM and EDR detections Focus on behaviors, not just indicators Threat Hunting\nBuild hunts around adversary tradecraft Prioritize based on likelihood and impact Incident Response\nAccelerate scoping and containment Improve attribution and confidence Vulnerability Management\nPrioritize patching based on active exploitation Align exposure with threat actor capability Final Thoughts\rThreat intelligence is only valuable when it drives action. The goal is not to know everything about the threat landscape, but to know the right things that help your organization detect faster, respond smarter, and reduce risk. When threat intelligence is tightly integrated with threat hunting, detection engineering, and incident response, it becomes a force multiplier rather than a reporting function.\n","date":"2025-12-19T00:00:00Z","image":"http://localhost:1313/post/threat-intelligence-101/ThreatIntelligence101_hu_51476f218a2574aa.png","permalink":"http://localhost:1313/post/threat-intelligence-101/","title":"Threat Intelligence 101"},{"content":"Overview\rWhat better way to kick this blog off than by providing an overview on threat hunting. It\u0026rsquo;s been done a thousand times before, but threat hunting is a crucial, and often misunderstood, component of security. The purpose of this introductory post is to simply define some key aspects of threat hunting and provide a general process for the threat hunting workflow.\nIn the modern cybersecurity landscape, traditional defensive solutions such as firewalls, IDS/IPS, and EDR are essential but insufficient. Sophisticated adversaries are constantly developing new methods for bypassing such automated defenses. Thus enters threat hunting, a hypothesis-driven and proactive strategy for identifying sophisticated threats. Threat hunting has become a core capability for mature security teams, bridging the gap between traditional detection and proactive defense. Unlike alert-driven monitoring, threat hunting assumes that adversaries may already be present in an environment and focuses on identifying malicious activity that has evaded existing controls.\nWhat is Threat Hunting?\rAt its core, threat hunting is a hypothesis-driven, proactive security activity aimed at identifying threats that bypass automated detections.\nThreat hunting differs from:\nSOC alert triage (reactive) Incident response (post-compromise) Threat intelligence consumption (contextual) Instead, threat hunting:\nStarts with an assumption of compromise/hypothesis Leverages telemetry across endpoints, identity, cloud, and network Focuses on behaviors, not just alerts - we\u0026rsquo;ll discuss indicators of attack vs indicators of compromise further down Threat hunting does not replace automated detection and response - it compliments it.\nWhy Threat Hunting?\rAs I\u0026rsquo;ve mentioned above, traditional security solutions simply are not sufficient on their own to disrupt sophisticated adversary activity. While firewalls, antivirus, and EDR systems are essential, they are primarily reactive — they wait for a known \u0026ldquo;signature\u0026rdquo; or alert to trigger. Sophisticated attackers know how to evade these triggers. By leveraging threat hunting capabilities, an organization can proactively find hidden attackers and advanced threats that bypass automated defenses, thus reducing dwell time, identifying security gaps, and disrupting adversary activity. Threat hunting is driven by an assumption of breach, which means operating under the premise that an adversary already has a foothold within a network.\nCore Concepts and Terminology\rReactive vs. Proactive\rWe\u0026rsquo;ll start with terms I\u0026rsquo;ve already mentioned several times: reactive vs. proactive.\nIncident response, in general, is reactive:\nAction is triggered by an alert/incident Relies on known signatures, rules, or other predefined detection logic Effective for known/commodity threats; limited for novel or low-and slow This would be akin to receiving a home security alert about an intruder in your home and then investigating. Threat hunting, on the other hand, is proactive:\nAction is initiated by an analyst\u0026rsquo;s hypotheses Seeks unknown/evasive threats - finding a needle in a needle stack Focuses on attacker behavior and tradecraft rather than signatures Ultimately improves detection logic/telemetry/security posture over time This would be akin to suspecting an intruder is in your home without receiving a security alert and going to check. The Pyramid of Pain\rThis model was created by David Bianco and provides a great visualization of the increasing difficulty adversaries face when you deny them certain indicators.\nThe Pyramid of Pain - David Bianco\nThe pyramid works its way up from lowest to highest impact. At the bottom half of the pyramid we have hash values, IP addresses, and domain names, all of which are rather inconsequential for an attacker to change. Threat hunting aims to operate at the top of the pyramid, focusing on adversary TTPs and actually disrupting how they operate. This causes the most \u0026ldquo;pain\u0026rdquo; for adversaries by forcing them to change their behaviors.\nIOCs vs IOAs\rThis is a crucial concept to understand. I\u0026rsquo;ve seen many junior hunters, or analysts seeking to transition from IR to hunting, struggle with this.\nIndicators of compromise (IOCs) are artifacts that suggest a breach has already happened and typically spur an incident response. These indicators are easy for adversaries to change and are typically only discovered post-compromise.\nExamples include:\nMalicious IPs or domains Malicious file hashes Known bad registry keys Indicators of attack (IOAs) focus on behavior associated with an active attack in progress or an emerging attack. Focusing on the behaviors associated with an attack make it harder for attackers to evade, and can even be effective in combating zero-days or custom tooling that would bypass signature detection.\nExamples include:\nCredential dumping from LSASS Abnormal parent-child process relationships Execution of unsigned modules from memory MITRE ATT\u0026amp;CK Framework\rEvery threat hunter should be intimately familiar with the MITRE ATT\u0026amp;CK framework. This incredible knowledge base catalogs adversary behavior across tactics, techniques, and sub-techniques. Tactics provide the why of an action, such as initial access or persistence. Techniques and sub-techniques provide how a tactic is achieved, such as process injection or command and scripting interpreter. This framework is crucial for threat hunters because we frequently use it to structure a hypothesis. For instance, suppose we know an adversary of interest has a tendency to achieve credential access by targeting credentials stored in the process memory of the LSASS. T1003.001 - OS Credential Dumping: LSASS Memory would provide a starting point.\nATT\u0026amp;CK Matrix for Enterprise – MITRE ATT\u0026amp;CK Framework\nThreat Hunting Methodologies\rNow that we\u0026rsquo;ve discussed how the pyramid of pain, IOAs, and the MITRE ATT\u0026amp;CK framework fit into threat hunting, let\u0026rsquo;s go over some different hunting methodologies. There are various approaches, and while no one way is \u0026ldquo;correct\u0026rdquo;, mature threat hunting teams will blend all them all.\nHypothesis-Driven Hunting\rThis is a creative and more mature approach to threat hunting. It begins with a question or a theory about a potential attack vector or adversary behavior. For example, you suspect/hypothesize that an attacker is abusing WMI to move laterally within your environment. You may then start to investigate for instances of WmiPrvSE.exe spawning cmd.exe or powershell.exe.\nIntelligence-Driven Hunting\rThis method is driven by external reporting, translating threat intelligence into behavioral queries. For example, if a recent report states that a specific APT is modifying registry key values to establish persistence, this could spur a hunt that searches for modification of the specific key.\nData-Driven/Machine Learning-Driven Hunting\rThese hunts use data science to identify anomalies. It requires appropriate baselining to establish \u0026ldquo;normal\u0026rdquo; behavior, and then investigating statistical outliers - such as thin-tailed and fat-tailed distribution. For example, spikes in outbound traffic could be indicative of data exfiltration.\nThreat Hunt Lifecycle\rThreat hunting is not random; it\u0026rsquo;s actually a structured, repeatable lifecycle.\n1. Hypothesis Development\nThe hunt begins with some sort of trigger to generate a testable hypothesis; this could be a newly reported vulnerability, a new technique added to MITRE ATT\u0026amp;CK, or even a gut feeling based on recent trends.\n2. Data Collection\nAfter forming a hypothesis, we must determine that the necessary data actually exists to test the hypothesis. For instance, we must identify the relevant telemetry sources: do we ingest EDR logs? Do we have Windows Event Logs? Do we have PCAP or NetFlow data? The necessary data must exist in order to conduct a hunt.\n3. Analysis and Validation\nOnce we\u0026rsquo;ve identified the necessary data, we being to query and pivot. As we work through the data, we must validate our findings and filter out known good behavior to identify and isolate malicious activity. As a simple example, if we are running a search and observe that svchost.exe appears 1,000 times, but svch0st.exe appears once, we need to identify and investigate that anomaly.\n4. Escalation\nOnce we\u0026rsquo;ve validated malicious findings, we typically escalate the activity to the incident response team. The threat hunters role upon escalation is to provide context surrounding the activity, such as relevant artifacts, timelining, remediation recommendations, etc.\n5. Detections and Feedback\nAt this point, threat hunters want to create and refine high-fidelity detection rules based on our hunt logic to identify and prevent reoccurring or future activity. This results in increased detection coverage and reduces gaps for your organization. We can also identify any shortcomings in our telemetry, such as improper sensor configurations or visibility gaps due to a lack of necessary logs.\n6. Documentation\nA hunt should always be documented; documentation turns a hunt into a key security asset for your organization by translating hunt logic into automated detections and ensuring reproducibility for your team. It provides evidence of impact and proof of value to justify the need for threat hunting operations.\nWhat Does A Successful Hunt Look Like?\rI cannot emphasize enough that the success of a hunt is not determined by whether or not an active threat was found. In fact, finding an active threat as a result of hunt efforts is quite rare. While that would be the \u0026ldquo;ideal\u0026rdquo; outcome, there are a number of other metrics that demonstrate the success of a hunt:\nIdentifying detection gaps and/or vulnerablities Improving visibility and telemetry Creating high-fidelity detections Validating assumptions Reducing future dwell time A successful hunt that did not illuminate an active threat should prove that an adversary isn\u0026rsquo;t present using the specific technique hunted on. What is key is that the hunt results in actionable improvements. With that said, let\u0026rsquo;s take a quick look at some common pitfalls that result in an unsuccessful hunt:\nHunting without a hypothesis Focusing heavily on IOCs rather than IOAs Overscoping queries without behavioral context Failing to document outcomes Lack of operational improvements Final Thoughts\rThreat hunting is the relentless pursuit of the unknown. It transitions security posture from a defensive mindset to an offensive one. By focusing on adversary behavior, leveraging frameworks like MITRE ATT\u0026amp;CK, and continuously refining detections, threat hunters can meaningfully disrupt sophisticated attackers and uncover threats that technology alone cannot catch.\n","date":"2025-12-16T00:00:00Z","image":"http://localhost:1313/post/threat-hunting-101/ThreatHunting101_hu_2c6ab15fd50a30e6.png","permalink":"http://localhost:1313/post/threat-hunting-101/","title":"Threat Hunting 101"}]